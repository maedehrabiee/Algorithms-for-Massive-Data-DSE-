{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qE0tJ_br5KA-",
        "outputId": "8ff15729-dd1c-448a-bbc1-7d8003a8a955"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "INSTALLING LIBRARIES\n",
            "================================================================================\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m89.2/89.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\n",
            "âœ“ datasketch installed\n",
            "\n",
            "âœ“ setup complete\n"
          ]
        }
      ],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# 1. SETUP AND INSTALLATION\n",
        "# Installing libraries we need for the project\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"INSTALLING LIBRARIES\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# install packages\n",
        "!pip install -q datasketch pandas matplotlib seaborn kaggle nltk\n",
        "\n",
        "# check if datasketch works\n",
        "try:\n",
        "    from datasketch import MinHash, MinHashLSH\n",
        "    print(\"\\nâœ“ datasketch installed\")\n",
        "except:\n",
        "    print(\"\\nâš  reinstalling datasketch...\")\n",
        "    !pip install --upgrade datasketch\n",
        "\n",
        "# download stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords', quiet=True)\n",
        "\n",
        "print(\"\\nâœ“ setup complete\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "qexwbN5-5del",
        "outputId": "a689c524-469e-4549-82c5-b7bc452940a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "KAGGLE AUTHENTICATION\n",
            "================================================================================\n",
            "\n",
            "ğŸ“¤ please upload your kaggle.json file\n",
            "get it from: https://www.kaggle.com/settings/account\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-553ff3d1-8f2d-486b-9934-5d6e08943eb5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-553ff3d1-8f2d-486b-9934-5d6e08943eb5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "\n",
            "âœ“ authentication successful\n"
          ]
        }
      ],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# 2.KAGGLE LOGIN\n",
        "# Upload your kaggle.json file to download the dataset\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"KAGGLE AUTHENTICATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nğŸ“¤ please upload your kaggle.json file\")\n",
        "print(\"get it from: https://www.kaggle.com/settings/account\\n\")\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "# setup kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "print(\"\\nâœ“ authentication successful\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MF4KMtPc5dg0",
        "outputId": "42026649-3826-419d-e354-70875f5551cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "DOWNLOADING DATASET\n",
            "================================================================================\n",
            "\n",
            "dataset: mohamedbakhet/amazon-books-reviews\n",
            "Dataset URL: https://www.kaggle.com/datasets/mohamedbakhet/amazon-books-reviews\n",
            "License(s): CC0-1.0\n",
            "Downloading amazon-books-reviews.zip to /content\n",
            " 99% 1.05G/1.06G [00:10<00:00, 301MB/s]\n",
            "100% 1.06G/1.06G [00:10<00:00, 111MB/s]\n",
            "\n",
            "âœ“ download complete\n",
            "  file: /content/Books_rating.csv\n",
            "  size: 2.66 GB\n"
          ]
        }
      ],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# 3.DOWNLOAD DATASET\n",
        "# Getting Amazon book reviews from Kaggle\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "import os\n",
        "\n",
        "dataset_name = \"mohamedbakhet/amazon-books-reviews\"\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"DOWNLOADING DATASET\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\ndataset: {dataset_name}\")\n",
        "\n",
        "# download and extract\n",
        "!kaggle datasets download -d {dataset_name} -p /content --unzip\n",
        "\n",
        "# check if file exists\n",
        "csv_file = \"/content/Books_rating.csv\"\n",
        "\n",
        "if os.path.exists(csv_file):\n",
        "    size_gb = os.path.getsize(csv_file) / (1024**3)\n",
        "    print(f\"\\nâœ“ download complete\")\n",
        "    print(f\"  file: {csv_file}\")\n",
        "    print(f\"  size: {size_gb:.2f} GB\")\n",
        "else:\n",
        "    print(\"âš  error: file not found\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeOGFYcO5djZ",
        "outputId": "bbdc7c98-b4d0-4441-8269-036a75690b08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "LOADING DATASET\n",
            "================================================================================\n",
            "\n",
            "âœ“ loaded dataset\n",
            "  rows: 3,000,000\n",
            "  columns: 10\n",
            "\n",
            "columns in dataset:\n",
            "  1. Id\n",
            "  2. Title\n",
            "  3. Price\n",
            "  4. User_id\n",
            "  5. profileName\n",
            "  6. review/helpfulness\n",
            "  7. review/score\n",
            "  8. review/time\n",
            "  9. review/summary\n",
            "  10. review/text\n"
          ]
        }
      ],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# 4.LOAD FULL DATASET\n",
        "# Reading the CSV file with all columns\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "csv_path = \"/content/Books_rating.csv\"\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"LOADING DATASET\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# load full dataset\n",
        "df_full = pd.read_csv(csv_path)\n",
        "\n",
        "print(f\"\\nâœ“ loaded dataset\")\n",
        "print(f\"  rows: {len(df_full):,}\")\n",
        "print(f\"  columns: {len(df_full.columns)}\")\n",
        "\n",
        "# show column names\n",
        "print(\"\\ncolumns in dataset:\")\n",
        "for i, col in enumerate(df_full.columns, 1):\n",
        "    print(f\"  {i}. {col}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7kpFYz-5utB",
        "outputId": "de03e8a5-6b68-4b9f-a422-a433623e2ed8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "FIRST 10 ROWS\n",
            "================================================================================\n",
            "\n",
            "           Id                           Title  Price         User_id  \\\n",
            "0  1882931173  Its Only Art If Its Well Hung!    NaN   AVCGYZL8FQQTD   \n",
            "1  0826414346        Dr. Seuss: American Icon    NaN  A30TK6U7DNS82R   \n",
            "2  0826414346        Dr. Seuss: American Icon    NaN  A3UH4UZ4RSVO82   \n",
            "3  0826414346        Dr. Seuss: American Icon    NaN  A2MVUWT453QH61   \n",
            "4  0826414346        Dr. Seuss: American Icon    NaN  A22X4XUPKF66MR   \n",
            "5  0826414346        Dr. Seuss: American Icon    NaN  A2F6NONFUDB6UK   \n",
            "6  0826414346        Dr. Seuss: American Icon    NaN  A14OJS0VWMOSWO   \n",
            "7  0826414346        Dr. Seuss: American Icon    NaN  A2RSSXTDZDUSH4   \n",
            "8  0826414346        Dr. Seuss: American Icon    NaN  A25MD5I2GUIW6W   \n",
            "9  0826414346        Dr. Seuss: American Icon    NaN  A3VA4XFS5WNJO3   \n",
            "\n",
            "                          profileName review/helpfulness  review/score  \\\n",
            "0               Jim of Oz \"jim-of-oz\"                7/7           4.0   \n",
            "1                       Kevin Killian              10/10           5.0   \n",
            "2                        John Granger              10/11           5.0   \n",
            "3  Roy E. Perry \"amateur philosopher\"                7/7           4.0   \n",
            "4     D. H. Richards \"ninthwavestore\"                3/3           4.0   \n",
            "5                              Malvin                2/2           4.0   \n",
            "6                 Midwest Book Review                3/4           5.0   \n",
            "7                           J. Squire                0/0           5.0   \n",
            "8           J. P. HIGBED \"big fellow\"                0/0           5.0   \n",
            "9                     Donald Burnside                3/5           4.0   \n",
            "\n",
            "   review/time                                     review/summary  \\\n",
            "0    940636800             Nice collection of Julie Strain images   \n",
            "1   1095724800                                  Really Enjoyed It   \n",
            "2   1078790400    Essential for every personal and Public Library   \n",
            "3   1090713600    Phlip Nel gives silly Seuss a serious treatment   \n",
            "4   1107993600                             Good academic overview   \n",
            "5   1127174400         One of America's greatest creative talents   \n",
            "6   1100131200  A memorably excellent survey of Dr. Seuss' man...   \n",
            "7   1231200000                              Academia At It's Best   \n",
            "8   1209859200           And to think that I read it on the tram!   \n",
            "9   1076371200            Fascinating account of a genius at work   \n",
            "\n",
            "                                         review/text  \n",
            "0  This is only for Julie Strain fans. It's a col...  \n",
            "1  I don't care much for Dr. Seuss but after read...  \n",
            "2  If people become the books they read and if \"t...  \n",
            "3  Theodore Seuss Geisel (1904-1991), aka &quot;D...  \n",
            "4  Philip Nel - Dr. Seuss: American IconThis is b...  \n",
            "5  \"Dr. Seuss: American Icon\" by Philip Nel is a ...  \n",
            "6  Theodor Seuss Giesel was best known as 'Dr. Se...  \n",
            "7  When I recieved this book as a gift for Christ...  \n",
            "8  Trams (or any public transport) are not usuall...  \n",
            "9  As far as I am aware, this is the first book-l...  \n"
          ]
        }
      ],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# 5.DISPLAY FIRST 10 ROWS\n",
        "# Looking at some examples from the dataset\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"FIRST 10 ROWS\")\n",
        "print(\"=\"*80)\n",
        "print()\n",
        "\n",
        "# show all columns\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "\n",
        "print(df_full.head(10))\n",
        "\n",
        "# reset display\n",
        "pd.reset_option('display.max_columns')\n",
        "pd.reset_option('display.width')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKnl_lt8oqrm",
        "outputId": "10a0052d-3075-446f-e0e1-c8a67e0c0300"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "NULL VALUES IN EACH COLUMN\n",
            "================================================================================\n",
            "\n",
            "column                         nulls      %         \n",
            "--------------------------------------------------\n",
            "Id                             0            0.00%\n",
            "Title                          208          0.01%\n",
            "Price                          2518829     83.96%\n",
            "User_id                        561787      18.73%\n",
            "profileName                    561905      18.73%\n",
            "review/helpfulness             0            0.00%\n",
            "review/score                   0            0.00%\n",
            "review/time                    0            0.00%\n",
            "review/summary                 407          0.01%\n",
            "review/text                    8            0.00%\n",
            "--------------------------------------------------\n",
            "TOTAL                          3643144   \n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# 6.NULL VALUES CHECK\n",
        "# Finding missing data in each column\n",
        "# =============================================================================\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"NULL VALUES IN EACH COLUMN\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# header line (pretty print)\n",
        "print(f\"\\n{'column':<30} {'nulls':<10} {'%':<10}\")\n",
        "print(\"-\"*50)\n",
        "\n",
        "# loop over columns and compute null stats\n",
        "for col in df_full.columns:\n",
        "    nulls = df_full[col].isna().sum()       # number of NaNs in this column\n",
        "    percent = (nulls / len(df_full) * 100) if len(df_full) else 0.0\n",
        "    print(f\"{col:<30} {nulls:<10} {percent:>6.2f}%\")\n",
        "\n",
        "# total missing cells in the whole dataframe\n",
        "total_nulls = df_full.isna().sum().sum()\n",
        "print(\"-\"*50)\n",
        "print(f\"{'TOTAL':<30} {total_nulls:<10}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IE1G_PR5x_o",
        "outputId": "a611591b-3a22-43f8-a839-f4d8f106e4e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "DUPLICATE VALUES IN EACH COLUMN\n",
            "================================================================================\n",
            "\n",
            "Column                         Unique       Duplicates  \n",
            "-------------------------------------------------------\n",
            "Id                             221,998      2,778,002   \n",
            "Title                          212,403      2,787,597   \n",
            "Price                          6,004        2,993,996   \n",
            "User_id                        1,008,972    1,991,028   \n",
            "profileName                    854,145      2,145,855   \n",
            "review/helpfulness             12,084       2,987,916   \n",
            "review/score                   5            2,999,995   \n",
            "review/time                    6,272        2,993,728   \n",
            "review/summary                 1,592,314    1,407,686   \n",
            "review/text                    2,062,648    937,352     \n"
          ]
        }
      ],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# 7.DUPLICATE VALUES CHECK\n",
        "# Finding how many duplicate values each column has\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"DUPLICATE VALUES IN EACH COLUMN\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\n{'Column':<30} {'Unique':<12} {'Duplicates':<12}\")\n",
        "print(\"-\"*55)\n",
        "\n",
        "for col in df_full.columns:\n",
        "    unique = df_full[col].nunique()\n",
        "    duplicates = len(df_full) - unique\n",
        "    print(f\"{col:<30} {unique:<12,} {duplicates:<12,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Isp8IcN5yCS",
        "outputId": "01ac2c19-8491-4948-c10f-7e44f3f0f5f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "COMPLETE ROW DUPLICATES\n",
            "================================================================================\n",
            "\n",
            "rows with all columns identical: 8,774\n",
            "percentage: 0.29%\n",
            "\n",
            "example of duplicate rows:\n",
            "             Id                               Title  Price         User_id  \\\n",
            "422  0671551345  Night World: Daughters Of Darkness    NaN             NaN   \n",
            "423  0671551345  Night World: Daughters Of Darkness    NaN             NaN   \n",
            "428  0671551345  Night World: Daughters Of Darkness    NaN             NaN   \n",
            "429  0671551345  Night World: Daughters Of Darkness    NaN             NaN   \n",
            "726  050552421X    The Scarletti Curse (Candleglow)    NaN  A1PURG5ASALH79   \n",
            "727  050552421X    The Scarletti Curse (Candleglow)    NaN  A1PURG5ASALH79   \n",
            "\n",
            "     profileName review/helpfulness  review/score  review/time  \\\n",
            "422          NaN                0/0           5.0    895968000   \n",
            "423          NaN                0/0           5.0    895968000   \n",
            "428          NaN                0/0           5.0    878601600   \n",
            "429          NaN                0/0           5.0    878601600   \n",
            "726  Kelly Owens                0/0           4.0    984182400   \n",
            "727  Kelly Owens                0/0           4.0    984182400   \n",
            "\n",
            "                    review/summary  \\\n",
            "422           EXCELLENT!!!!!!!!!!!   \n",
            "423           EXCELLENT!!!!!!!!!!!   \n",
            "428            One of my Favorites   \n",
            "429            One of my Favorites   \n",
            "726  a good start for a new series   \n",
            "727  a good start for a new series   \n",
            "\n",
            "                                           review/text  \n",
            "422  This book was outstanding! I couldn't put it d...  \n",
            "423  This book was outstanding! I couldn't put it d...  \n",
            "428  I was sceptical about this book at first, I ha...  \n",
            "429  I was sceptical about this book at first, I ha...  \n",
            "726  I first started reading mrs. feehan thru her w...  \n",
            "727  I first started reading mrs. feehan thru her w...  \n"
          ]
        }
      ],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# 8.COMPLETE ROW DUPLICATES\n",
        "# Finding rows where ALL columns are identical\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"COMPLETE ROW DUPLICATES\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# count rows where all columns match\n",
        "complete_dupes = df_full.duplicated().sum()\n",
        "\n",
        "print(f\"\\nrows with all columns identical: {complete_dupes:,}\")\n",
        "print(f\"percentage: {(complete_dupes / len(df_full)) * 100:.2f}%\")\n",
        "\n",
        "# show example if there are duplicates\n",
        "if complete_dupes > 0:\n",
        "    print(\"\\nexample of duplicate rows:\")\n",
        "    dup_rows = df_full[df_full.duplicated(keep=False)].head(6)\n",
        "    print(dup_rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVIW_-A15yEe",
        "outputId": "f84d10d8-87bf-4b92-b257-6bfd417cb242"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "CLEANING DATA\n",
            "================================================================================\n",
            "\n",
            "âœ“ removed 8,774 complete duplicate rows\n",
            "âœ“ selected 2 columns: Id, review/text\n",
            "âœ“ removed 8 rows with null values\n",
            "\n",
            "âœ“ final clean dataset: 2,991,218 rows\n",
            "\n",
            "âœ“ exported to: /content/clean_reviews.csv\n",
            "\n",
            "================================================================================\n",
            "FIRST 10 ROWS OF CLEAN DATA\n",
            "================================================================================\n",
            "\n",
            "    review_id                                        review_text\n",
            "0  1882931173  This is only for Julie Strain fans. It's a col...\n",
            "1  0826414346  I don't care much for Dr. Seuss but after read...\n",
            "2  0826414346  If people become the books they read and if \"t...\n",
            "3  0826414346  Theodore Seuss Geisel (1904-1991), aka &quot;D...\n",
            "4  0826414346  Philip Nel - Dr. Seuss: American IconThis is b...\n",
            "5  0826414346  \"Dr. Seuss: American Icon\" by Philip Nel is a ...\n",
            "6  0826414346  Theodor Seuss Giesel was best known as 'Dr. Se...\n",
            "7  0826414346  When I recieved this book as a gift for Christ...\n",
            "8  0826414346  Trams (or any public transport) are not usuall...\n",
            "9  0826414346  As far as I am aware, this is the first book-l...\n"
          ]
        }
      ],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# 9.DATA CLEANING AND EXPORT\n",
        "# Removing complete duplicates and saving 2 columns\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"CLEANING DATA\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# remove rows where ALL columns are identical\n",
        "initial = len(df_full)\n",
        "df_clean = df_full.drop_duplicates()  # no subset = checks all columns\n",
        "removed = initial - len(df_clean)\n",
        "\n",
        "print(f\"\\nâœ“ removed {removed:,} complete duplicate rows\")\n",
        "\n",
        "# select only 2 columns we need\n",
        "df_clean = df_clean[['Id', 'review/text']].copy()\n",
        "print(f\"âœ“ selected 2 columns: Id, review/text\")\n",
        "\n",
        "# remove nulls in these columns\n",
        "initial = len(df_clean)\n",
        "df_clean = df_clean.dropna()\n",
        "removed = initial - len(df_clean)\n",
        "print(f\"âœ“ removed {removed:,} rows with null values\")\n",
        "\n",
        "# rename columns\n",
        "df_clean = df_clean.rename(columns={\n",
        "    'Id': 'review_id',\n",
        "    'review/text': 'review_text'\n",
        "})\n",
        "\n",
        "df_clean = df_clean.reset_index(drop=True)\n",
        "\n",
        "print(f\"\\nâœ“ final clean dataset: {len(df_clean):,} rows\")\n",
        "\n",
        "# export to CSV\n",
        "output_file = '/content/clean_reviews.csv'\n",
        "df_clean.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"\\nâœ“ exported to: {output_file}\")\n",
        "\n",
        "# show first 10 rows of clean data\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"FIRST 10 ROWS OF CLEAN DATA\")\n",
        "print(\"=\"*80)\n",
        "print()\n",
        "print(df_clean.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZG1pKFh5yGz",
        "outputId": "fe2c38b9-11bb-4f92-b917-e306d5cdccf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "SAMPLING DATA\n",
            "================================================================================\n",
            "\n",
            "âœ“ sampled 29,912 reviews (1.0%)\n",
            "  memory: 26.7 MB\n",
            "\n",
            "first 5 reviews in sample:\n",
            "    review_id                                        review_text\n",
            "0  B0006E8SE0  In ATOMIC CITY Terry Rosen remembers his years...\n",
            "1  B000PW7KJW  Authoritative, covers topics Jews and others w...\n",
            "2  B000FFJRI6  This book almost broke me, it was like 13 mydr...\n",
            "3  B000K0BJKU  Island of the blue dolphins by Scott O'Dell is...\n",
            "4  1587243938  I have heard so much about this book but never...\n"
          ]
        }
      ],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# 10.SAMPLING\n",
        "# Taking a small sample to work with (1% of data)\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "sample_fraction = 0.01  # 1%\n",
        "random_seed = 42\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"SAMPLING DATA\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# take random sample\n",
        "np.random.seed(random_seed)\n",
        "df_sample = df_clean.sample(frac=sample_fraction, random_state=random_seed)\n",
        "df_sample = df_sample.reset_index(drop=True)\n",
        "\n",
        "print(f\"\\nâœ“ sampled {len(df_sample):,} reviews ({sample_fraction*100}%)\")\n",
        "print(f\"  memory: {df_sample.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
        "\n",
        "# show first few\n",
        "print(\"\\nfirst 5 reviews in sample:\")\n",
        "print(df_sample.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "r_stWKVh97mR"
      },
      "outputs": [],
      "source": [
        "#-------------------------------------------------------------------------------\n",
        "# 11.TEXT NORMALIZATION\n",
        "# make lowercase + remove punctuation + collapse spaces\n",
        "# =============================================================================\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = set(stopwords.words('english'))  # used in shingling (word-level)\n",
        "\n",
        "def normalize_text(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r'[^a-z0-9\\s]', ' ', text)     # keep letters/digits/spaces\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()     # collapse multiple spaces\n",
        "    return text\n",
        "\n",
        "df_sample['text_norm'] = df_sample['review_text'].apply(normalize_text)\n",
        "df_sample = df_sample[df_sample['text_norm'].str.len() > 0].reset_index(drop=True)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "fWeN81bY8gLo",
        "outputId": "c55b4a46-e6d5-4548-993c-b34ec8960a21"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    review_id                                        review_text  \\\n",
              "0  B0006E8SE0  In ATOMIC CITY Terry Rosen remembers his years...   \n",
              "1  B000PW7KJW  Authoritative, covers topics Jews and others w...   \n",
              "2  B000FFJRI6  This book almost broke me, it was like 13 mydr...   \n",
              "3  B000K0BJKU  Island of the blue dolphins by Scott O'Dell is...   \n",
              "4  1587243938  I have heard so much about this book but never...   \n",
              "5  B000N5BN4O  This is my favorite comic and I was really exc...   \n",
              "6  B0000DK4HN  This is not a novel, it is a silly justificati...   \n",
              "7  B000MWTM28  I was fascinated to know some details about th...   \n",
              "8  B000OTPE62  Widower Luke Becker had decided that his eleve...   \n",
              "9  0130256684  It is a book, what do you want from me? Thanks...   \n",
              "\n",
              "                                           text_norm  \\\n",
              "0  in atomic city terry rosen remembers his years...   \n",
              "1  authoritative covers topics jews and others wo...   \n",
              "2  this book almost broke me it was like 13 mydra...   \n",
              "3  island of the blue dolphins by scott o dell is...   \n",
              "4  i have heard so much about this book but never...   \n",
              "5  this is my favorite comic and i was really exc...   \n",
              "6  this is not a novel it is a silly justificatio...   \n",
              "7  i was fascinated to know some details about th...   \n",
              "8  widower luke becker had decided that his eleve...   \n",
              "9  it is a book what do you want from me thanks i...   \n",
              "\n",
              "                                            shingles  num_shingles  \n",
              "0  {edward teller enrico, father works long, like...            88  \n",
              "1  {focus well written, topics jews others, cover...             7  \n",
              "2  {almost broke like, left eyes shell, like loga...            31  \n",
              "3  {dell exciting book, wilddogs left alone, woul...            74  \n",
              "4  {tipping point perhaps, common tipping point, ...           146  \n",
              "5  {favorite comic really, around 20 pounds, othe...            40  \n",
              "6  {know better next, time last richard, patterso...            17  \n",
              "7  {pure search play, search 4 different, compare...            74  \n",
              "8  {widower luke becker, canon letters however, r...            63  \n",
              "9  {book want thanks, book said thanks, want than...             4  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-712c036f-4309-4999-9ab0-39fcf1fd7fcf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>review_text</th>\n",
              "      <th>text_norm</th>\n",
              "      <th>shingles</th>\n",
              "      <th>num_shingles</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B0006E8SE0</td>\n",
              "      <td>In ATOMIC CITY Terry Rosen remembers his years...</td>\n",
              "      <td>in atomic city terry rosen remembers his years...</td>\n",
              "      <td>{edward teller enrico, father works long, like...</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B000PW7KJW</td>\n",
              "      <td>Authoritative, covers topics Jews and others w...</td>\n",
              "      <td>authoritative covers topics jews and others wo...</td>\n",
              "      <td>{focus well written, topics jews others, cover...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B000FFJRI6</td>\n",
              "      <td>This book almost broke me, it was like 13 mydr...</td>\n",
              "      <td>this book almost broke me it was like 13 mydra...</td>\n",
              "      <td>{almost broke like, left eyes shell, like loga...</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B000K0BJKU</td>\n",
              "      <td>Island of the blue dolphins by Scott O'Dell is...</td>\n",
              "      <td>island of the blue dolphins by scott o dell is...</td>\n",
              "      <td>{dell exciting book, wilddogs left alone, woul...</td>\n",
              "      <td>74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1587243938</td>\n",
              "      <td>I have heard so much about this book but never...</td>\n",
              "      <td>i have heard so much about this book but never...</td>\n",
              "      <td>{tipping point perhaps, common tipping point, ...</td>\n",
              "      <td>146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>B000N5BN4O</td>\n",
              "      <td>This is my favorite comic and I was really exc...</td>\n",
              "      <td>this is my favorite comic and i was really exc...</td>\n",
              "      <td>{favorite comic really, around 20 pounds, othe...</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>B0000DK4HN</td>\n",
              "      <td>This is not a novel, it is a silly justificati...</td>\n",
              "      <td>this is not a novel it is a silly justificatio...</td>\n",
              "      <td>{know better next, time last richard, patterso...</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>B000MWTM28</td>\n",
              "      <td>I was fascinated to know some details about th...</td>\n",
              "      <td>i was fascinated to know some details about th...</td>\n",
              "      <td>{pure search play, search 4 different, compare...</td>\n",
              "      <td>74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>B000OTPE62</td>\n",
              "      <td>Widower Luke Becker had decided that his eleve...</td>\n",
              "      <td>widower luke becker had decided that his eleve...</td>\n",
              "      <td>{widower luke becker, canon letters however, r...</td>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0130256684</td>\n",
              "      <td>It is a book, what do you want from me? Thanks...</td>\n",
              "      <td>it is a book what do you want from me thanks i...</td>\n",
              "      <td>{book want thanks, book said thanks, want than...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-712c036f-4309-4999-9ab0-39fcf1fd7fcf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-712c036f-4309-4999-9ab0-39fcf1fd7fcf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-712c036f-4309-4999-9ab0-39fcf1fd7fcf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-34844ee0-5cde-464e-b8b0-093824e4affd\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-34844ee0-5cde-464e-b8b0-093824e4affd')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-34844ee0-5cde-464e-b8b0-093824e4affd button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_sample",
              "summary": "{\n  \"name\": \"df_sample\",\n  \"rows\": 29912,\n  \"fields\": [\n    {\n      \"column\": \"review_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 17355,\n        \"samples\": [\n          \"1893858243\",\n          \"0966074483\",\n          \"0582417902\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 29608,\n        \"samples\": [\n          \"Recently I had a friend for dinner and prepared one of the recipes from this wonderful cookbook, Joy of Cooking. We all loved it and she asked for the recipe since she knew her children, too, would enjoy it. Instead of writing out the recipe, I decided to purchase the book as a gift for her. I purchased my copy many years ago, and it is the one cookbook I go to whenever I have a question about food. I love the \\\"About...\\\" sections throughout the book. I have learned so much. I also go to this cookbook when I'm having company, as I know I can rely on the recipes to be a success.\",\n          \"A psychologist builds and uses a time machine to travel 800,000-30 million years into the future. It is made of Ivory, Crystal, and Nickel, with two levers for control. I found his turning the hypocritical Victorian society inside out to be refreshing and made the book a fast page turner. His not using overly technical language was another plus. The future society he described was intruiging and scary in its extremes. The gentle Eloi being taken care of by the slavish Morlocks makes the reader think of other historical eras where the few parasitically lived off the many. Feudalism and Communism come to mind. But, in this world the Eloi send their own on a regular basis to be fed to the canabalistic Morlocks. This book makes the reader think and encourages one to want to read more about both history and other fiction novels. For that alone, it deserves four and a half stars.\",\n          \"I finally took the time (quick read) to read the book that Apocolipse Now was based on. Great book. The insites into human nature; our dark side, our prejudices is worth the time it takes to read.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text_norm\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 29608,\n        \"samples\": [\n          \"recently i had a friend for dinner and prepared one of the recipes from this wonderful cookbook joy of cooking we all loved it and she asked for the recipe since she knew her children too would enjoy it instead of writing out the recipe i decided to purchase the book as a gift for her i purchased my copy many years ago and it is the one cookbook i go to whenever i have a question about food i love the about sections throughout the book i have learned so much i also go to this cookbook when i m having company as i know i can rely on the recipes to be a success\",\n          \"a psychologist builds and uses a time machine to travel 800 000 30 million years into the future it is made of ivory crystal and nickel with two levers for control i found his turning the hypocritical victorian society inside out to be refreshing and made the book a fast page turner his not using overly technical language was another plus the future society he described was intruiging and scary in its extremes the gentle eloi being taken care of by the slavish morlocks makes the reader think of other historical eras where the few parasitically lived off the many feudalism and communism come to mind but in this world the eloi send their own on a regular basis to be fed to the canabalistic morlocks this book makes the reader think and encourages one to want to read more about both history and other fiction novels for that alone it deserves four and a half stars\",\n          \"i finally took the time quick read to read the book that apocolipse now was based on great book the insites into human nature our dark side our prejudices is worth the time it takes to read\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"shingles\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_shingles\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 87,\n        \"min\": 1,\n        \"max\": 1832,\n        \"num_unique_values\": 602,\n        \"samples\": [\n          144,\n          347,\n          383\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "#------------------------------------------------------------------------------\n",
        "# 12.SHINGLING (word-level, k=3)\n",
        "# build a set of 3-word shingles from the normalized text\n",
        "# =============================================================================\n",
        "k = 3\n",
        "\n",
        "def create_shingles_from_norm(norm_text, k=3):\n",
        "    words = norm_text.split()                          # already lower+clean\n",
        "    words = [w for w in words if w not in stop_words]  # remove stopwords\n",
        "    if len(words) < k:\n",
        "        return {' '.join(words)} if words else set()\n",
        "    return {' '.join(words[i:i+k]) for i in range(len(words) - k + 1)}\n",
        "\n",
        "df_sample['shingles']     = df_sample['text_norm'].apply(create_shingles_from_norm)\n",
        "df_sample['num_shingles'] = df_sample['shingles'].apply(len)\n",
        "df_sample = df_sample[df_sample['num_shingles'] > 0].reset_index(drop=True)\n",
        "\n",
        "df_sample.head(10)   #  first 10 rows\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muE7MSE79721",
        "outputId": "c6c63298-b6d8-49b1-bdde-2ed9cf95be7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "CREATING MINHASH SIGNATURES\n",
            "================================================================================\n",
            "  signature size: 128 hash values\n",
            "  compression: 0.6x\n"
          ]
        }
      ],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# 13.MINHASH SIGNATURES\n",
        "# Creating compact signatures from shingles\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "from datasketch import MinHash\n",
        "\n",
        "num_perm = 128  # signature size\n",
        "\n",
        "def create_minhash(shingles):\n",
        "    m = MinHash(num_perm=num_perm)\n",
        "    for shingle in shingles:\n",
        "        m.update(shingle.encode('utf-8'))\n",
        "    return m\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"CREATING MINHASH SIGNATURES\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "\n",
        "df_sample['minhash'] = df_sample['shingles'].apply(create_minhash)\n",
        "\n",
        "\n",
        "print(f\"  signature size: {num_perm} hash values\")\n",
        "print(f\"  compression: {df_sample['num_shingles'].mean() / num_perm:.1f}x\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gjx3jfKzHuV3",
        "outputId": "0b6ecbd9-6b8b-4e34-fa59-34759dc8ad22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            " LSH INDEX CONSTRUCTION\n",
            "================================================================================\n",
            "\n",
            "configuration:\n",
            "  similarity threshold: 0.6\n",
            "  signature size: 128\n",
            "\n",
            "âœ“ created unique keys for 29,912 documents\n",
            "\n",
            "ğŸ“Š lsh parameters (auto-calculated):\n",
            "  number of bands (b): 18\n",
            "  rows per band (r): 7\n",
            "  verification: b Ã— r = 18 Ã— 7 (should equal 128)\n"
          ]
        }
      ],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "#  14.LSH INDEX CONSTRUCTION\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "from datasketch import MinHashLSH\n",
        "\n",
        "# LSH configuration\n",
        "THRESHOLD = 0.6  # jaccard similarity threshold for candidate pairs\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" LSH INDEX CONSTRUCTION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\nconfiguration:\")\n",
        "print(f\"  similarity threshold: {THRESHOLD}\")\n",
        "print(f\"  signature size: {num_perm}\")\n",
        "\n",
        "# create unique identifiers for lsh indexing\n",
        "# format: book_id + \"_\" + row_index\n",
        "# this ensures each review has a unique key while preserving book information\n",
        "df_sample['unique_key'] = df_sample['review_id'] + \"_\" + df_sample.index.astype(str)\n",
        "\n",
        "print(f\"\\nâœ“ created unique keys for {len(df_sample):,} documents\")\n",
        "\n",
        "# verify key uniqueness\n",
        "duplicate_keys = df_sample['unique_key'].duplicated().sum()\n",
        "if duplicate_keys > 0:\n",
        "    print(f\"âš  warning: found {duplicate_keys} duplicate keys\")\n",
        "    df_sample = df_sample.drop_duplicates(subset=['unique_key'], keep='first')\n",
        "    print(f\"  removed duplicates, {len(df_sample):,} documents remain\")\n",
        "\n",
        "# initialize lsh index with similarity threshold\n",
        "lsh = MinHashLSH(threshold=THRESHOLD, num_perm=num_perm)\n",
        "\n",
        "\n",
        "# insert all documents into lsh index\n",
        "for idx, row in df_sample.iterrows():\n",
        "    lsh.insert(row['unique_key'], row['minhash'])\n",
        "\n",
        "\n",
        "\n",
        "print(f\"\\nğŸ“Š lsh parameters (auto-calculated):\")\n",
        "print(f\"  number of bands (b): {lsh.b}\")\n",
        "print(f\"  rows per band (r): {lsh.r}\")\n",
        "print(f\"  verification: b Ã— r = {lsh.b} Ã— {lsh.r} (should equal {num_perm})\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69HUXi9oZ_VM",
        "outputId": "75cd1421-5ff1-47a2-89a8-09971ba656f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            " CANDIDATE PAIR GENERATION\n",
            "================================================================================\n",
            "  Total possible pairs: 447,348,916\n",
            "  Candidate pairs (LSH): 331\n"
          ]
        }
      ],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "#  15.CANDIDATE PAIR GENERATION\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" CANDIDATE PAIR GENERATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "\n",
        "candidate_pairs = set()\n",
        "\n",
        "# Query LSH for each document\n",
        "for idx, row in df_sample.iterrows():\n",
        "    # Find candidates that hash to same bucket in at least one band\n",
        "    candidates = lsh.query(row['minhash'])\n",
        "\n",
        "    for candidate_key in candidates:\n",
        "        # Exclude self-pairs\n",
        "        if candidate_key != row['unique_key']:\n",
        "            # Sort keys to avoid duplicate pairs: (A,B) and (B,A)\n",
        "            pair = tuple(sorted([row['unique_key'], candidate_key]))\n",
        "            candidate_pairs.add(pair)\n",
        "\n",
        "candidate_pairs = list(candidate_pairs)\n",
        "\n",
        "\n",
        "# Calculate search efficiency improvement\n",
        "total_possible = len(df_sample) * (len(df_sample) - 1) // 2\n",
        "reduction_pct = (1 - len(candidate_pairs) / total_possible) * 100\n",
        "\n",
        "print(f\"  Total possible pairs: {total_possible:,}\")\n",
        "print(f\"  Candidate pairs (LSH): {len(candidate_pairs):,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5d6oQVLc07k",
        "outputId": "7003eab1-c7a7-4b74-b90a-ef5f20389078"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "STEP 12: VERIFYING SIMILARITY\n",
            "================================================================================\n",
            "\n",
            "Threshold: 0.6\n",
            "Candidate pairs to check: 331\n"
          ]
        }
      ],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# 16. SETUP FOR SIMILARITY VERIFICATION\n",
        "# Setting up tools and thresholds\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"STEP 12: VERIFYING SIMILARITY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Set threshold (reuse from LSH or default to 0.6)\n",
        "try:\n",
        "    THRESHOLD = THRESHOLD  # From LSH cell\n",
        "except NameError:\n",
        "    THRESHOLD = 0.6\n",
        "\n",
        "print(f\"\\nThreshold: {THRESHOLD}\")\n",
        "print(f\"Candidate pairs to check: {len(candidate_pairs):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VlOQJQtc1NU",
        "outputId": "ceb9c521-74f4-4dc0-f4aa-1ea0b6e87a80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ Function ready\n"
          ]
        }
      ],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# 17. JACCARD SIMILARITY FUNCTION\n",
        "# Calculates exact similarity between two sets\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "def jaccard_similarity(set1, set2):\n",
        "    \"\"\"Calculate Jaccard similarity: |A âˆ© B| / |A âˆª B|\"\"\"\n",
        "\n",
        "    # Handle empty sets\n",
        "    if not set1 and not set2:\n",
        "        return 1.0\n",
        "\n",
        "    # Calculate intersection and union\n",
        "    intersection = len(set1 & set2)\n",
        "    union = len(set1 | set2)\n",
        "\n",
        "    # Return ratio\n",
        "    return intersection / union if union > 0 else 0.0\n",
        "\n",
        "print(\"âœ“ Function ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "cDWGzh12c1Ql",
        "outputId": "e1097f60-a2f2-435b-a48b-c9e8bd06acbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ Created lookups for 29,912 documents\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    review_id                                        review_text  \\\n",
              "0  B0006E8SE0  In ATOMIC CITY Terry Rosen remembers his years...   \n",
              "1  B000PW7KJW  Authoritative, covers topics Jews and others w...   \n",
              "2  B000FFJRI6  This book almost broke me, it was like 13 mydr...   \n",
              "3  B000K0BJKU  Island of the blue dolphins by Scott O'Dell is...   \n",
              "4  1587243938  I have heard so much about this book but never...   \n",
              "5  B000N5BN4O  This is my favorite comic and I was really exc...   \n",
              "6  B0000DK4HN  This is not a novel, it is a silly justificati...   \n",
              "7  B000MWTM28  I was fascinated to know some details about th...   \n",
              "8  B000OTPE62  Widower Luke Becker had decided that his eleve...   \n",
              "9  0130256684  It is a book, what do you want from me? Thanks...   \n",
              "\n",
              "                                           text_norm  \\\n",
              "0  in atomic city terry rosen remembers his years...   \n",
              "1  authoritative covers topics jews and others wo...   \n",
              "2  this book almost broke me it was like 13 mydra...   \n",
              "3  island of the blue dolphins by scott o dell is...   \n",
              "4  i have heard so much about this book but never...   \n",
              "5  this is my favorite comic and i was really exc...   \n",
              "6  this is not a novel it is a silly justificatio...   \n",
              "7  i was fascinated to know some details about th...   \n",
              "8  widower luke becker had decided that his eleve...   \n",
              "9  it is a book what do you want from me thanks i...   \n",
              "\n",
              "                                            shingles  num_shingles  \\\n",
              "0  {edward teller enrico, father works long, like...            88   \n",
              "1  {focus well written, topics jews others, cover...             7   \n",
              "2  {almost broke like, left eyes shell, like loga...            31   \n",
              "3  {dell exciting book, wilddogs left alone, woul...            74   \n",
              "4  {tipping point perhaps, common tipping point, ...           146   \n",
              "5  {favorite comic really, around 20 pounds, othe...            40   \n",
              "6  {know better next, time last richard, patterso...            17   \n",
              "7  {pure search play, search 4 different, compare...            74   \n",
              "8  {widower luke becker, canon letters however, r...            63   \n",
              "9  {book want thanks, book said thanks, want than...             4   \n",
              "\n",
              "                                             minhash    unique_key  \n",
              "0  <datasketch.minhash.MinHash object at 0x78326e...  B0006E8SE0_0  \n",
              "1  <datasketch.minhash.MinHash object at 0x7832c9...  B000PW7KJW_1  \n",
              "2  <datasketch.minhash.MinHash object at 0x78328d...  B000FFJRI6_2  \n",
              "3  <datasketch.minhash.MinHash object at 0x78328c...  B000K0BJKU_3  \n",
              "4  <datasketch.minhash.MinHash object at 0x783250...  1587243938_4  \n",
              "5  <datasketch.minhash.MinHash object at 0x783250...  B000N5BN4O_5  \n",
              "6  <datasketch.minhash.MinHash object at 0x783250...  B0000DK4HN_6  \n",
              "7  <datasketch.minhash.MinHash object at 0x783250...  B000MWTM28_7  \n",
              "8  <datasketch.minhash.MinHash object at 0x783250...  B000OTPE62_8  \n",
              "9  <datasketch.minhash.MinHash object at 0x783250...  0130256684_9  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3f835dca-eeed-4525-8db7-a9c493a06f4f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>review_text</th>\n",
              "      <th>text_norm</th>\n",
              "      <th>shingles</th>\n",
              "      <th>num_shingles</th>\n",
              "      <th>minhash</th>\n",
              "      <th>unique_key</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B0006E8SE0</td>\n",
              "      <td>In ATOMIC CITY Terry Rosen remembers his years...</td>\n",
              "      <td>in atomic city terry rosen remembers his years...</td>\n",
              "      <td>{edward teller enrico, father works long, like...</td>\n",
              "      <td>88</td>\n",
              "      <td>&lt;datasketch.minhash.MinHash object at 0x78326e...</td>\n",
              "      <td>B0006E8SE0_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B000PW7KJW</td>\n",
              "      <td>Authoritative, covers topics Jews and others w...</td>\n",
              "      <td>authoritative covers topics jews and others wo...</td>\n",
              "      <td>{focus well written, topics jews others, cover...</td>\n",
              "      <td>7</td>\n",
              "      <td>&lt;datasketch.minhash.MinHash object at 0x7832c9...</td>\n",
              "      <td>B000PW7KJW_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B000FFJRI6</td>\n",
              "      <td>This book almost broke me, it was like 13 mydr...</td>\n",
              "      <td>this book almost broke me it was like 13 mydra...</td>\n",
              "      <td>{almost broke like, left eyes shell, like loga...</td>\n",
              "      <td>31</td>\n",
              "      <td>&lt;datasketch.minhash.MinHash object at 0x78328d...</td>\n",
              "      <td>B000FFJRI6_2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B000K0BJKU</td>\n",
              "      <td>Island of the blue dolphins by Scott O'Dell is...</td>\n",
              "      <td>island of the blue dolphins by scott o dell is...</td>\n",
              "      <td>{dell exciting book, wilddogs left alone, woul...</td>\n",
              "      <td>74</td>\n",
              "      <td>&lt;datasketch.minhash.MinHash object at 0x78328c...</td>\n",
              "      <td>B000K0BJKU_3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1587243938</td>\n",
              "      <td>I have heard so much about this book but never...</td>\n",
              "      <td>i have heard so much about this book but never...</td>\n",
              "      <td>{tipping point perhaps, common tipping point, ...</td>\n",
              "      <td>146</td>\n",
              "      <td>&lt;datasketch.minhash.MinHash object at 0x783250...</td>\n",
              "      <td>1587243938_4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>B000N5BN4O</td>\n",
              "      <td>This is my favorite comic and I was really exc...</td>\n",
              "      <td>this is my favorite comic and i was really exc...</td>\n",
              "      <td>{favorite comic really, around 20 pounds, othe...</td>\n",
              "      <td>40</td>\n",
              "      <td>&lt;datasketch.minhash.MinHash object at 0x783250...</td>\n",
              "      <td>B000N5BN4O_5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>B0000DK4HN</td>\n",
              "      <td>This is not a novel, it is a silly justificati...</td>\n",
              "      <td>this is not a novel it is a silly justificatio...</td>\n",
              "      <td>{know better next, time last richard, patterso...</td>\n",
              "      <td>17</td>\n",
              "      <td>&lt;datasketch.minhash.MinHash object at 0x783250...</td>\n",
              "      <td>B0000DK4HN_6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>B000MWTM28</td>\n",
              "      <td>I was fascinated to know some details about th...</td>\n",
              "      <td>i was fascinated to know some details about th...</td>\n",
              "      <td>{pure search play, search 4 different, compare...</td>\n",
              "      <td>74</td>\n",
              "      <td>&lt;datasketch.minhash.MinHash object at 0x783250...</td>\n",
              "      <td>B000MWTM28_7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>B000OTPE62</td>\n",
              "      <td>Widower Luke Becker had decided that his eleve...</td>\n",
              "      <td>widower luke becker had decided that his eleve...</td>\n",
              "      <td>{widower luke becker, canon letters however, r...</td>\n",
              "      <td>63</td>\n",
              "      <td>&lt;datasketch.minhash.MinHash object at 0x783250...</td>\n",
              "      <td>B000OTPE62_8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0130256684</td>\n",
              "      <td>It is a book, what do you want from me? Thanks...</td>\n",
              "      <td>it is a book what do you want from me thanks i...</td>\n",
              "      <td>{book want thanks, book said thanks, want than...</td>\n",
              "      <td>4</td>\n",
              "      <td>&lt;datasketch.minhash.MinHash object at 0x783250...</td>\n",
              "      <td>0130256684_9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3f835dca-eeed-4525-8db7-a9c493a06f4f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3f835dca-eeed-4525-8db7-a9c493a06f4f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3f835dca-eeed-4525-8db7-a9c493a06f4f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a9ca16da-be1e-4f3c-8c82-7e09fc7b7dbf\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a9ca16da-be1e-4f3c-8c82-7e09fc7b7dbf')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a9ca16da-be1e-4f3c-8c82-7e09fc7b7dbf button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_sample",
              "summary": "{\n  \"name\": \"df_sample\",\n  \"rows\": 29912,\n  \"fields\": [\n    {\n      \"column\": \"review_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 17355,\n        \"samples\": [\n          \"1893858243\",\n          \"0966074483\",\n          \"0582417902\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 29608,\n        \"samples\": [\n          \"Recently I had a friend for dinner and prepared one of the recipes from this wonderful cookbook, Joy of Cooking. We all loved it and she asked for the recipe since she knew her children, too, would enjoy it. Instead of writing out the recipe, I decided to purchase the book as a gift for her. I purchased my copy many years ago, and it is the one cookbook I go to whenever I have a question about food. I love the \\\"About...\\\" sections throughout the book. I have learned so much. I also go to this cookbook when I'm having company, as I know I can rely on the recipes to be a success.\",\n          \"A psychologist builds and uses a time machine to travel 800,000-30 million years into the future. It is made of Ivory, Crystal, and Nickel, with two levers for control. I found his turning the hypocritical Victorian society inside out to be refreshing and made the book a fast page turner. His not using overly technical language was another plus. The future society he described was intruiging and scary in its extremes. The gentle Eloi being taken care of by the slavish Morlocks makes the reader think of other historical eras where the few parasitically lived off the many. Feudalism and Communism come to mind. But, in this world the Eloi send their own on a regular basis to be fed to the canabalistic Morlocks. This book makes the reader think and encourages one to want to read more about both history and other fiction novels. For that alone, it deserves four and a half stars.\",\n          \"I finally took the time (quick read) to read the book that Apocolipse Now was based on. Great book. The insites into human nature; our dark side, our prejudices is worth the time it takes to read.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text_norm\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 29608,\n        \"samples\": [\n          \"recently i had a friend for dinner and prepared one of the recipes from this wonderful cookbook joy of cooking we all loved it and she asked for the recipe since she knew her children too would enjoy it instead of writing out the recipe i decided to purchase the book as a gift for her i purchased my copy many years ago and it is the one cookbook i go to whenever i have a question about food i love the about sections throughout the book i have learned so much i also go to this cookbook when i m having company as i know i can rely on the recipes to be a success\",\n          \"a psychologist builds and uses a time machine to travel 800 000 30 million years into the future it is made of ivory crystal and nickel with two levers for control i found his turning the hypocritical victorian society inside out to be refreshing and made the book a fast page turner his not using overly technical language was another plus the future society he described was intruiging and scary in its extremes the gentle eloi being taken care of by the slavish morlocks makes the reader think of other historical eras where the few parasitically lived off the many feudalism and communism come to mind but in this world the eloi send their own on a regular basis to be fed to the canabalistic morlocks this book makes the reader think and encourages one to want to read more about both history and other fiction novels for that alone it deserves four and a half stars\",\n          \"i finally took the time quick read to read the book that apocolipse now was based on great book the insites into human nature our dark side our prejudices is worth the time it takes to read\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"shingles\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_shingles\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 87,\n        \"min\": 1,\n        \"max\": 1832,\n        \"num_unique_values\": 602,\n        \"samples\": [\n          144,\n          347,\n          383\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"minhash\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"unique_key\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 29912,\n        \"samples\": [\n          \"0684818701_20631\",\n          \"1929229488_8387\",\n          \"B00089TUN6_27043\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# 18. CREATE LOOKUP DICTIONARIES\n",
        "# Fast access to shingles and text by key\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "# Build shingle dictionary: key â†’ set of shingles\n",
        "shingle_dict = df_sample.set_index('unique_key')['shingles'].to_dict()\n",
        "\n",
        "# Build text dictionary: key â†’ review text\n",
        "text_dict = df_sample.set_index('unique_key')['review_text'].to_dict()\n",
        "\n",
        "print(f\"âœ“ Created lookups for {len(shingle_dict):,} documents\")\n",
        "\n",
        "# Show first 10 rows\n",
        "df_sample.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0o1bhwWCc1TM",
        "outputId": "0b6e7f70-7fbd-4705-8592-0103f794a8e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before: 331 pairs\n",
            "After:  331 unique pairs\n",
            "Removed: 0 duplicates\n"
          ]
        }
      ],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# 19. NORMALIZE PAIRS\n",
        "# Remove duplicates and self-pairs\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "clean_pairs = set()\n",
        "\n",
        "for key1, key2 in candidate_pairs:\n",
        "    # Skip if same document\n",
        "    if key1 == key2:\n",
        "        continue\n",
        "\n",
        "    # Sort keys to avoid duplicates\n",
        "    pair = tuple(sorted([key1, key2]))\n",
        "    clean_pairs.add(pair)\n",
        "\n",
        "# Convert back to list\n",
        "clean_pairs = list(clean_pairs)\n",
        "\n",
        "print(f\"Before: {len(candidate_pairs):,} pairs\")\n",
        "print(f\"After:  {len(clean_pairs):,} unique pairs\")\n",
        "print(f\"Removed: {len(candidate_pairs) - len(clean_pairs):,} duplicates\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GB8QmmJd4W5",
        "outputId": "5a9a8b8c-197c-4647-875b-a367470f672d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ Found 331 similar pairs (â‰¥0.6)\n"
          ]
        }
      ],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# 20. VERIFY EACH PAIR\n",
        "# Calculate true Jaccard and filter by threshold\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "verified_pairs = []\n",
        "\n",
        "# Check each candidate pair\n",
        "for key1, key2 in clean_pairs:\n",
        "\n",
        "    # Get shingle sets\n",
        "    shingles1 = shingle_dict.get(key1)\n",
        "    shingles2 = shingle_dict.get(key2)\n",
        "\n",
        "    # Skip if missing\n",
        "    if shingles1 is None or shingles2 is None:\n",
        "        continue\n",
        "\n",
        "    # Calculate exact similarity\n",
        "    sim = jaccard_similarity(shingles1, shingles2)\n",
        "\n",
        "    # Keep only if above threshold\n",
        "    if sim >= THRESHOLD:\n",
        "        verified_pairs.append({\n",
        "            'key1': key1,\n",
        "            'key2': key2,\n",
        "            'similarity': sim,\n",
        "            'text1': text_dict[key1],\n",
        "            'text2': text_dict[key2]\n",
        "        })\n",
        "\n",
        "print(f\"âœ“ Found {len(verified_pairs):,} similar pairs (â‰¥{THRESHOLD})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3X0_h-7Id80X",
        "outputId": "5a516340-cc10-4624-e68b-b0e00cf770bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“Š Similarity Statistics:\n",
            "  Mean:   0.994\n",
            "  Median: 1.000\n",
            "  Min:    0.667\n",
            "  Max:    1.000\n"
          ]
        }
      ],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# 21. BUILD RESULTS TABLE\n",
        "# Organize verified pairs into dataframe\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "# Create dataframe from list of dictionaries\n",
        "results_df = pd.DataFrame(verified_pairs)\n",
        "\n",
        "# Sort by similarity (highest first)\n",
        "if len(results_df) > 0:\n",
        "    results_df = results_df.sort_values('similarity', ascending=False)\n",
        "    results_df = results_df.reset_index(drop=True)\n",
        "\n",
        "    print(f\"\\nğŸ“Š Similarity Statistics:\")\n",
        "    print(f\"  Mean:   {results_df['similarity'].mean():.3f}\")\n",
        "    print(f\"  Median: {results_df['similarity'].median():.3f}\")\n",
        "    print(f\"  Min:    {results_df['similarity'].min():.3f}\")\n",
        "    print(f\"  Max:    {results_df['similarity'].max():.3f}\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nâš  No similar pairs found\")\n",
        "    print(\"  Try: Lower threshold or larger sample\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUcSn2BmeBEz",
        "outputId": "33b718b2-d880-4c04-f777-9c4aa9306ee7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "SIMILARITY DISTRIBUTION\n",
            "============================================================\n",
            "\n",
            "Range           Count      %         \n",
            "-----------------------------------\n",
            "0.60-0.65       0            0.0%\n",
            "0.65-0.70       1            0.3%\n",
            "0.70-0.75       3            0.9%\n",
            "0.75-0.80       0            0.0%\n",
            "0.80-0.85       2            0.6%\n",
            "0.85-0.90       0            0.0%\n",
            "0.90-0.95       5            1.5%\n",
            "0.95-1.00       320         96.7%\n",
            "-----------------------------------\n",
            "TOTAL           331        100.0%\n"
          ]
        }
      ],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# 22. ANALYZE DISTRIBUTION\n",
        "# How many pairs in each similarity range?\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "if len(results_df) > 0:\n",
        "\n",
        "    print(\"=\"*60)\n",
        "    print(\"SIMILARITY DISTRIBUTION\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Define ranges\n",
        "    ranges = [\n",
        "        (0.60, 0.65, '0.60-0.65'),\n",
        "        (0.65, 0.70, '0.65-0.70'),\n",
        "        (0.70, 0.75, '0.70-0.75'),\n",
        "        (0.75, 0.80, '0.75-0.80'),\n",
        "        (0.80, 0.85, '0.80-0.85'),\n",
        "        (0.85, 0.90, '0.85-0.90'),\n",
        "        (0.90, 0.95, '0.90-0.95'),\n",
        "        (0.95, 1.00, '0.95-1.00')\n",
        "    ]\n",
        "\n",
        "    print(f\"\\n{'Range':<15} {'Count':<10} {'%':<10}\")\n",
        "    print(\"-\"*35)\n",
        "\n",
        "    # Count pairs in each range\n",
        "    for low, high, label in ranges:\n",
        "        if high < 1.0:\n",
        "            mask = (results_df['similarity'] >= low) & (results_df['similarity'] < high)\n",
        "        else:\n",
        "            mask = results_df['similarity'] >= low\n",
        "\n",
        "        count = mask.sum()\n",
        "        pct = (count / len(results_df)) * 100\n",
        "        print(f\"{label:<15} {count:<10} {pct:>5.1f}%\")\n",
        "\n",
        "    print(\"-\"*35)\n",
        "    print(f\"{'TOTAL':<15} {len(results_df):<10} {'100.0%':>5}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XgNwFoSeHby",
        "outputId": "11cd3f24-e7b0-4c40-c239-5889340df306"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "TOP 5 MOST SIMILAR PAIRS\n",
            "================================================================================\n",
            "\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "PAIR #1 - Similarity: 1.000\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "Review 1:\n",
            "  I enjoyed reading this book in high school and also enjoy watching one of the old B&W; movie versions if it happens to come on TV. So I decided to rea...\n",
            "\n",
            "Review 2:\n",
            "  I enjoyed reading this book in high school and also enjoy watching one of the old B&W; movie versions if it happens to come on TV. So I decided to rea...\n",
            "\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "PAIR #2 - Similarity: 1.000\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "Review 1:\n",
            "  First of all: I wish people would stop deconstructing Oscar Wilde before they deconstruct his message. He should be free to contradict himself, becaus...\n",
            "\n",
            "Review 2:\n",
            "  First of all: I wish people would stop deconstructing Oscar Wilde before they deconstruct his message. He should be free to contradict himself, becaus...\n",
            "\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "PAIR #3 - Similarity: 1.000\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "Review 1:\n",
            "  \"Take care my skirt don't trip you up...\"\"Don't Meg pull fair?\"\"Oh, yes she tries to but she don't love Bethy as I do...\"If you're looking for a copy ...\n",
            "\n",
            "Review 2:\n",
            "  \"Take care my skirt don't trip you up...\"\"Don't Meg pull fair?\"\"Oh, yes she tries to but she don't love Bethy as I do...\"If you're looking for a copy ...\n",
            "\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "PAIR #4 - Similarity: 1.000\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "Review 1:\n",
            "  Even the best authors in the world sometimes put out something that... well, isn't up to their usual standards. For Jane Austen, that book was \"Mansfi...\n",
            "\n",
            "Review 2:\n",
            "  Even the best authors in the world sometimes put out something that... well, isn't up to their usual standards. For Jane Austen, that book was \"Mansfi...\n",
            "\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "PAIR #5 - Similarity: 1.000\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "Review 1:\n",
            "  In Jane Austen's time, young women were taught that it was practically their duty to \"marry well\" -- someone of at least equal social/financial standi...\n",
            "\n",
            "Review 2:\n",
            "  In Jane Austen's time, young women were taught that it was practically their duty to \"marry well\" -- someone of at least equal social/financial standi...\n"
          ]
        }
      ],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# 23.  SHOW TOP 5 MOST SIMILAR PAIRS\n",
        "# Display the reviews that are most alike\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "if len(results_df) > 0:\n",
        "\n",
        "    print(\"=\"*80)\n",
        "    print(\"TOP 5 MOST SIMILAR PAIRS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Show first 5 rows\n",
        "    for i, row in results_df.head(5).iterrows():\n",
        "\n",
        "        print(f\"\\n{'â”€'*80}\")\n",
        "        print(f\"PAIR #{i+1} - Similarity: {row['similarity']:.3f}\")\n",
        "        print(f\"{'â”€'*80}\")\n",
        "\n",
        "        # Show first 150 characters of each review\n",
        "        print(f\"\\nReview 1:\")\n",
        "        print(f\"  {row['text1'][:150]}...\")\n",
        "\n",
        "        print(f\"\\nReview 2:\")\n",
        "        print(f\"  {row['text2'][:150]}...\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nâš  No results to display\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mABUDPXOeHfG",
        "outputId": "9a0c9491-3ccb-456e-ac9f-5c9cebbf89e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "SHINGLE OVERLAP DETAILS\n",
            "================================================================================\n",
            "\n",
            "Pair #1:\n",
            "  Common shingles:      34 (100.0%)\n",
            "  Only in review 1:      0\n",
            "  Only in review 2:      0\n",
            "  Total unique:         34\n",
            "\n",
            "Pair #2:\n",
            "  Common shingles:      37 (100.0%)\n",
            "  Only in review 1:      0\n",
            "  Only in review 2:      0\n",
            "  Total unique:         37\n",
            "\n",
            "Pair #3:\n",
            "  Common shingles:      72 (100.0%)\n",
            "  Only in review 1:      0\n",
            "  Only in review 2:      0\n",
            "  Total unique:         72\n",
            "\n",
            "Pair #4:\n",
            "  Common shingles:     268 (100.0%)\n",
            "  Only in review 1:      0\n",
            "  Only in review 2:      0\n",
            "  Total unique:        268\n",
            "\n",
            "Pair #5:\n",
            "  Common shingles:     293 (100.0%)\n",
            "  Only in review 1:      0\n",
            "  Only in review 2:      0\n",
            "  Total unique:        293\n"
          ]
        }
      ],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# 24. DETAILED SHINGLE ANALYSIS\n",
        "# How many shingles match between pairs?\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "if len(results_df) > 0:\n",
        "\n",
        "    print(\"=\"*80)\n",
        "    print(\"SHINGLE OVERLAP DETAILS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Analyze first 5 pairs\n",
        "    for i, row in results_df.head(5).iterrows():\n",
        "\n",
        "        # Get shingle sets\n",
        "        s1 = shingle_dict[row['key1']]\n",
        "        s2 = shingle_dict[row['key2']]\n",
        "\n",
        "        # Calculate overlap\n",
        "        common = s1 & s2\n",
        "        only_1 = s1 - s2\n",
        "        only_2 = s2 - s1\n",
        "        total = s1 | s2\n",
        "\n",
        "        print(f\"\\nPair #{i+1}:\")\n",
        "        print(f\"  Common shingles:    {len(common):>4} ({len(common)/len(total)*100:>5.1f}%)\")\n",
        "        print(f\"  Only in review 1:   {len(only_1):>4}\")\n",
        "        print(f\"  Only in review 2:   {len(only_2):>4}\")\n",
        "        print(f\"  Total unique:       {len(total):>4}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# 25. LOWEST SIMILARITY PAIRS\n",
        "# Pairs that barely meet the threshold - SHOWING FULL TEXT\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "if len(results_df) > 0:\n",
        "\n",
        "    print(\"=\"*80)\n",
        "    print(\"5 PAIRS WITH LOWEST SIMILARITY\")\n",
        "    print(f\"(but still â‰¥ {THRESHOLD})\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Get last 5 rows (lowest similarity)\n",
        "    for i, row in results_df.tail(5).iterrows():\n",
        "\n",
        "        print(f\"\\n{'â”€'*80}\")\n",
        "        print(f\"Pair #{i+1} - Similarity: {row['similarity']:.3f}\")\n",
        "        print(f\"{'â”€'*80}\")\n",
        "\n",
        "        # SHOW FULL TEXT - NO CHARACTER LIMIT\n",
        "        print(f\"\\nReview 1 (FULL TEXT):\")\n",
        "        print(f\"{row['text1']}\")\n",
        "\n",
        "        print(f\"\\n{'-'*80}\")\n",
        "\n",
        "        print(f\"\\nReview 2 (FULL TEXT):\")\n",
        "        print(f\"{row['text2']}\")\n",
        "\n",
        "        # Why are these barely similar?\n",
        "        s1 = shingle_dict[row['key1']]\n",
        "        s2 = shingle_dict[row['key2']]\n",
        "\n",
        "        print(f\"\\n{'â”€'*80}\")\n",
        "        print(f\"Analysis:\")\n",
        "        print(f\"  Review 1 has: {len(s1)} shingles\")\n",
        "        print(f\"  Review 2 has: {len(s2)} shingles\")\n",
        "        print(f\"  In common:    {len(s1 & s2)} shingles ({len(s1 & s2)/len(s1 | s2)*100:.1f}%)\")\n",
        "        print(f\"{'â”€'*80}\")\n",
        "\n",
        "        # Optional: Show common shingles\n",
        "        common_shingles = s1 & s2\n",
        "        if common_shingles:\n",
        "            print(f\"\\nCommon shingles (first 10):\")\n",
        "            for idx, shingle in enumerate(list(common_shingles)[:10], 1):\n",
        "                print(f\"  {idx}. '{shingle}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTOVkMVkhr1r",
        "outputId": "39d838de-93f5-4702-96cf-e8305e15f525"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "5 PAIRS WITH LOWEST SIMILARITY\n",
            "(but still â‰¥ 0.6)\n",
            "================================================================================\n",
            "\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Pair #327 - Similarity: 0.800\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "Review 1 (FULL TEXT):\n",
            "Perfect. How many more words must I write to be polite? Seriously, if one is satisfiedstop with the word requirements!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Review 2 (FULL TEXT):\n",
            "Excellent. How many more words must I write to be polite? Seriously, if one is satisfiedstop with the word requirements!\n",
            "\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Analysis:\n",
            "  Review 1 has: 9 shingles\n",
            "  Review 2 has: 9 shingles\n",
            "  In common:    8 shingles (80.0%)\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "Common shingles (first 10):\n",
            "  1. 'must write polite'\n",
            "  2. 'many words must'\n",
            "  3. 'words must write'\n",
            "  4. 'write polite seriously'\n",
            "  5. 'polite seriously one'\n",
            "  6. 'one satisfiedstop word'\n",
            "  7. 'satisfiedstop word requirements'\n",
            "  8. 'seriously one satisfiedstop'\n",
            "\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Pair #328 - Similarity: 0.723\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "Review 1 (FULL TEXT):\n",
            "Louisa May Alcott wrote many books, but \"Little Women\" retains a special place in the heart of American literature. Her warmly realistic stories, sense of comedy and tragedy, and insights into human nature make the romance, humor and sweet stories of \"Little Women\" come alive.The four March girls -- practical Meg, rambunctious Jo, sweet Beth and childish artist Amy -- live in genteel poverty with their mother Marmee; their father is away in the Civil War. Despite having little money, the girls keep their spirits up with writing, gardening, homemade plays, and the occasional romp with wealthier pals. Their pal, \"poor little rich boy\" Laurie, joins in and becomes their adoptive brother, as the girls deal with Meg's first romance, Beth's life-threatening illness, and fears for their father's safety.The second half of the book opens with Meg's wedding (if not to the man of her dreams, then to the man she loves). Things rapidly go awry after the wedding, when Laurie admits his true feelings to Jo -- only to be rejected. Distraught, he leaves; Amy also leaves on a trip to Europe with a picky old relative. Despite the deterioration of Beth's health, Jo makes her way into a job as a governess, seeking to put her treasured writing into print -- and finds her destiny as well.There's a clearly autobiographical tone to \"Little Women.\" Not surprising -- the March girls really are like the girls next door. Alcott wrote them with flaws and strengths, and their misadventures -- like Amy's embarrassing problem with her huge lobster -- have the feeling of authenticity. How much of it is real? A passage late in the book portrays Alcott -- in the form of Jo -- \"scribbling\" down the book itself, and getting it published because it feels so real and true.Sure, usually classics are hard to read. But \"Little Women\" is mainly daunting because of its length; the actual stories flow nicely and smoothly. Don't think it's just a book for teenage girls, either -- adults and boys can appreciate it as well. There's something for everyone: drama, romance, humor, sad and happy endings alike.Alcott's writing itself is nicely detailed. While certain items are no longer in common use (what IS a charabanc anyway?), Alcott's stories themselves seem very fresh and could easily be seen in a modern home. And as nauseating as \"heartwarming\" stories sometimes are, these definitely qualify. Sometimes, especially in the beginning, Alcott is a bit too preachy and hamhanded. But her touch becomes defter as she writes on.Jo is the quintessential tomboy, and the best character in the book: rough, gawky, fun-loving, impulsive, with a love of literature and a mouth that is slightly too big. Meg's love of luxury adds a flaw to the \"perfect little homemaker\" image, and Beth just avoids being shown as too saintly. Amy is an annoying little brat throughout much of the first half of the book, but by her teens she's almost as good as Jo.\"Little Women\" is one of those rare classic novels that is still relevant, funny, fresh and heartbreaking today. Louisa May Alcott's best-known novel is a magnificent achievement.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Review 2 (FULL TEXT):\n",
            "Louisa May Alcott wrote many books, but &quot;Little Women&quot; retains a special place in the heart of American literature. Her warmly realistic stories, sense of comedy and tragedy, and insights into human nature make the romance, humor and sweet stories of &quot;Little Women&quot; come alive.The four March girls -- practical Meg, rambunctious Jo, sweet Beth and childish artist Amy -- live in genteel poverty with their mother Marmee; their father is away in the Civil War. Despite having little money, the girls keep their spirits up with writing, gardening, homemade plays, and the occasional romp with wealthier pals. Their pal, &quot;poor little rich boy&quot; Laurie, joins in and becomes their adoptive brother, as the girls deal with Meg's first romance, Beth's life-threatening illness, and fears for their father's safety.The second half of the book opens with Meg's wedding (if not to the man of her dreams, then to the man she loves). Things rapidly go awry after the wedding, when Laurie admits his true feelings to Jo -- only to be rejected. Distraught, he leaves; Amy also leaves on a trip to Europe with a picky old relative. Despite the deterioration of Beth's health, Jo makes her way into a job as a governess, seeking to put her treasured writing into print -- and finds her destiny as well.There's a clearly autobiographical tone to &quot;Little Women.&quot; Not surprising -- the March girls really are like the girls next door. Alcott wrote them with flaws and strengths, and their misadventures -- like Amy's embarrassing problem with her huge lobster -- have the feeling of authenticity. How much of it is real? A passage late in the book portrays Alcott -- in the form of Jo -- &quot;scribbling&quot; down the book itself, and getting it published because it feels so real and true.Sure, usually classics are hard to read. But &quot;Little Women&quot; is mainly daunting because of its length; the actual stories flow nicely and smoothly. Don't think it's just a book for teenage girls, either -- adults and boys can appreciate it as well. There's something for everyone: drama, romance, humor, sad and happy endings alike.Alcott's writing itself is nicely detailed. While certain items are no longer in common use (what IS a charabanc anyway?), Alcott's stories themselves seem very fresh and could easily be seen in a modern home. And as nauseating as &quot;heartwarming&quot; stories sometimes are, these definitely qualify. Sometimes, especially in the beginning, Alcott is a bit too preachy and hamhanded. But her touch becomes defter as she writes on.Jo is the quintessential tomboy, and the best character in the book: rough, gawky, fun-loving, impulsive, with a love of literature and a mouth that is slightly too big. Meg's love of luxury adds a flaw to the &quot;perfect little homemaker&quot; image, and Beth just avoids being shown as too saintly. Amy is an annoying little brat throughout much of the first half of the book, but by her teens she's almost as good as Jo.&quot;Little Women&quot; is one of those rare period novels that is still relevant, funny, and heartbreaking today. Fun, sweet, and a beautiful experience.\n",
            "\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Analysis:\n",
            "  Review 1 has: 308 shingles\n",
            "  Review 2 has: 314 shingles\n",
            "  In common:    261 shingles (72.3%)\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "Common shingles (first 10):\n",
            "  1. 'fresh could easily'\n",
            "  2. 'slightly big meg'\n",
            "  3. 'problem huge lobster'\n",
            "  4. 'qualify sometimes especially'\n",
            "  5. 'life threatening illness'\n",
            "  6. 'humor sweet stories'\n",
            "  7. 'dreams man loves'\n",
            "  8. 'spirits writing gardening'\n",
            "  9. 'amy live genteel'\n",
            "  10. 'money girls keep'\n",
            "\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Pair #329 - Similarity: 0.723\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "Review 1 (FULL TEXT):\n",
            "Louisa May Alcott wrote many books, but &quot;Little Women&quot; retains a special place in the heart of American literature. Her warmly realistic stories, sense of comedy and tragedy, and insights into human nature make the romance, humor and sweet stories of &quot;Little Women&quot; come alive.The four March girls -- practical Meg, rambunctious Jo, sweet Beth and childish artist Amy -- live in genteel poverty with their mother Marmee; their father is away in the Civil War. Despite having little money, the girls keep their spirits up with writing, gardening, homemade plays, and the occasional romp with wealthier pals. Their pal, &quot;poor little rich boy&quot; Laurie, joins in and becomes their adoptive brother, as the girls deal with Meg's first romance, Beth's life-threatening illness, and fears for their father's safety.The second half of the book opens with Meg's wedding (if not to the man of her dreams, then to the man she loves). Things rapidly go awry after the wedding, when Laurie admits his true feelings to Jo -- only to be rejected. Distraught, he leaves; Amy also leaves on a trip to Europe with a picky old relative. Despite the deterioration of Beth's health, Jo makes her way into a job as a governess, seeking to put her treasured writing into print -- and finds her destiny as well.There's a clearly autobiographical tone to &quot;Little Women.&quot; Not surprising -- the March girls really are like the girls next door. Alcott wrote them with flaws and strengths, and their misadventures -- like Amy's embarrassing problem with her huge lobster -- have the feeling of authenticity. How much of it is real? A passage late in the book portrays Alcott -- in the form of Jo -- &quot;scribbling&quot; down the book itself, and getting it published because it feels so real and true.Sure, usually classics are hard to read. But &quot;Little Women&quot; is mainly daunting because of its length; the actual stories flow nicely and smoothly. Don't think it's just a book for teenage girls, either -- adults and boys can appreciate it as well. There's something for everyone: drama, romance, humor, sad and happy endings alike.Alcott's writing itself is nicely detailed. While certain items are no longer in common use (what IS a charabanc anyway?), Alcott's stories themselves seem very fresh and could easily be seen in a modern home. And as nauseating as &quot;heartwarming&quot; stories sometimes are, these definitely qualify. Sometimes, especially in the beginning, Alcott is a bit too preachy and hamhanded. But her touch becomes defter as she writes on.Jo is the quintessential tomboy, and the best character in the book: rough, gawky, fun-loving, impulsive, with a love of literature and a mouth that is slightly too big. Meg's love of luxury adds a flaw to the &quot;perfect little homemaker&quot; image, and Beth just avoids being shown as too saintly. Amy is an annoying little brat throughout much of the first half of the book, but by her teens she's almost as good as Jo.&quot;Little Women&quot; is one of those rare period novels that is still relevant, funny, and heartbreaking today. Fun, sweet, and a beautiful experience.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Review 2 (FULL TEXT):\n",
            "Louisa May Alcott wrote many books, but \"Little Women\" retains a special place in the heart of American literature. Her warmly realistic stories, sense of comedy and tragedy, and insights into human nature make the romance, humor and sweet stories of \"Little Women\" come alive.The four March girls -- practical Meg, rambunctious Jo, sweet Beth and childish artist Amy -- live in genteel poverty with their mother Marmee; their father is away in the Civil War. Despite having little money, the girls keep their spirits up with writing, gardening, homemade plays, and the occasional romp with wealthier pals. Their pal, \"poor little rich boy\" Laurie, joins in and becomes their adoptive brother, as the girls deal with Meg's first romance, Beth's life-threatening illness, and fears for their father's safety.The second half of the book opens with Meg's wedding (if not to the man of her dreams, then to the man she loves). Things rapidly go awry after the wedding, when Laurie admits his true feelings to Jo -- only to be rejected. Distraught, he leaves; Amy also leaves on a trip to Europe with a picky old relative. Despite the deterioration of Beth's health, Jo makes her way into a job as a governess, seeking to put her treasured writing into print -- and finds her destiny as well.There's a clearly autobiographical tone to \"Little Women.\" Not surprising -- the March girls really are like the girls next door. Alcott wrote them with flaws and strengths, and their misadventures -- like Amy's embarrassing problem with her huge lobster -- have the feeling of authenticity. How much of it is real? A passage late in the book portrays Alcott -- in the form of Jo -- \"scribbling\" down the book itself, and getting it published because it feels so real and true.Sure, usually classics are hard to read. But \"Little Women\" is mainly daunting because of its length; the actual stories flow nicely and smoothly. Don't think it's just a book for teenage girls, either -- adults and boys can appreciate it as well. There's something for everyone: drama, romance, humor, sad and happy endings alike.Alcott's writing itself is nicely detailed. While certain items are no longer in common use (what IS a charabanc anyway?), Alcott's stories themselves seem very fresh and could easily be seen in a modern home. And as nauseating as \"heartwarming\" stories sometimes are, these definitely qualify. Sometimes, especially in the beginning, Alcott is a bit too preachy and hamhanded. But her touch becomes defter as she writes on.Jo is the quintessential tomboy, and the best character in the book: rough, gawky, fun-loving, impulsive, with a love of literature and a mouth that is slightly too big. Meg's love of luxury adds a flaw to the \"perfect little homemaker\" image, and Beth just avoids being shown as too saintly. Amy is an annoying little brat throughout much of the first half of the book, but by her teens she's almost as good as Jo.\"Little Women\" is one of those rare classic novels that is still relevant, funny, fresh and heartbreaking today. Louisa May Alcott's best-known novel is a magnificent achievement.\n",
            "\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Analysis:\n",
            "  Review 1 has: 314 shingles\n",
            "  Review 2 has: 308 shingles\n",
            "  In common:    261 shingles (72.3%)\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "Common shingles (first 10):\n",
            "  1. 'fresh could easily'\n",
            "  2. 'slightly big meg'\n",
            "  3. 'problem huge lobster'\n",
            "  4. 'qualify sometimes especially'\n",
            "  5. 'life threatening illness'\n",
            "  6. 'humor sweet stories'\n",
            "  7. 'dreams man loves'\n",
            "  8. 'spirits writing gardening'\n",
            "  9. 'amy live genteel'\n",
            "  10. 'money girls keep'\n",
            "\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Pair #330 - Similarity: 0.701\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "Review 1 (FULL TEXT):\n",
            "\"Eleanor of Aquitaine and the Four Kings\" has been an important source book for perhaps the majority of authors who have written about this extraordinary woman during the past six decades. This book may have been the most important component of Amy Ruth Kelly's academic work. She was a Harvard scholar, close to retirement when her magnum opus went to press circa 1950.A careful reading shows that much of Ms. Kelly's text is original in the sense that she was diligent in exploring manuscripts and early histories, borrowing relatively little from her contemporary historians. She pioneered modern Eleanor scholarship.The author was the product of a more genteel age, a fact which her style betrays. It is curiously antique in places, but easy to read and to follow. For example, she introduces the word \"Paraclete\" without explanation: she herself needed no introduction to the school of Peter Abelard. Her book includes a number of dated curiosities: for example she refers to the Turkish port from which Eleanor sailed to Antioch as Satalia, rather than the modern day Antalya.Several modern scholars think Ms. Kelly got the Court of Ladies wrong. I disagree. I believe that she got it partly right. In fact the true nature of Eleanor's Court of Ladies at Poitiers is still the subject of debate. Personally, I believe that the late Claude Marks, the author of \"Pilgrims, heretics, and lovers: A medieval journey\" came close to reasonable truth on this topic.\"Eleanor of Aquitaine and the Four Kings\" is informative. It can still compete with more recent, \"pure\" biographies such as Allison Weir's \"Eleanor of Aquitaine: A Life,\" and Marion Meade's \"Eleanor of Aquitaine: A Biography.\" Modern historians have added many facts to the life and times of Eleanor of Aquitaine since Ms. Kelly published her title a lifetime ago. But she left us a record that feels true to life, entertaining and wise.Robert Fripp, Author of ...\"Power of a Woman. Memoirs of a turbulent life: Eleanor of Aquitaine\"\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Review 2 (FULL TEXT):\n",
            "Just about every author who has written about Eleanor of Aquitaine during the past six decades has used \"Eleanor of Aquitaine and the Four Kings\" as a source. This book may have been the most important component of Amy Ruth Kelly's academic work. She was a scholar, close to retirement when her magnum opus went to press in 1950.A careful reading shows that much of Ms. Kelly's text is original in the sense that she was diligent in exploring manuscripts and early histories. She pioneered modern Eleanor scholarship.The author was the product of a more genteel age, a fact which her style betrays. It is curiously antique in places, and on rare occasions she assumes a level of knowledge many readers may lack. For example, she introduces the word \"Paraclete\" without explanation: she herself needed no introduction to the school of Peter Abelard. Her book includes a number of dated curiosities: for example she refers to the Turkish port from which Eleanor sailed to Antioch as Satalia, rather than the modern day Antalya.Several modern scholars think Ms. Kelly got the Court of Ladies wrong. I disagree. I believe that she got it partly right. In fact the true nature of Eleanor's Court of Ladies at Poitiers is still the subject of debate. Personally, I believe that the late Claude Marks, the author of \"Pilgrims, heretics, and lovers: A medieval journey\" came close to reasonable truth on this topic. And Marks' estimate is not far from Kelly's.\"Eleanor of Aquitaine and the Four Kings\" is informative. It can still compete with more recent, \"pure\" biographies such as Allison Weir's \"Eleanor of Aquitaine: A Life,\" and Marion Meade's \"Eleanor of Aquitaine: A Biography.\" Modern historians have added many facts to the life and times of Eleanor of Aquitaine since Ms. Kelly published her title a lifetime ago. But she left us a record that feels true to life, entertaining and wise.Robert Fripp, Author of ...\"Power of a Woman. Memoirs of a turbulent life: Eleanor of Aquitaine\"\n",
            "\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Analysis:\n",
            "  Review 1 has: 190 shingles\n",
            "  Review 2 has: 191 shingles\n",
            "  In common:    157 shingles (70.1%)\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "Common shingles (first 10):\n",
            "  1. 'ladies wrong disagree'\n",
            "  2. 'eleanor sailed antioch'\n",
            "  3. 'woman memoirs turbulent'\n",
            "  4. 'close reasonable truth'\n",
            "  5. 'allison weir eleanor'\n",
            "  6. 'shows much ms'\n",
            "  7. 'claude marks author'\n",
            "  8. 'eleanor scholarship author'\n",
            "  9. 'component amy ruth'\n",
            "  10. 'needed introduction school'\n",
            "\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Pair #331 - Similarity: 0.667\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "Review 1 (FULL TEXT):\n",
            "Easy to get on my Kindle and to transport it everywhere. Rapid download to all my connected electronics. And you cannot go wrong with so little money for it. Love those classics.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Review 2 (FULL TEXT):\n",
            "Easy to get on my Kindle and to transport it everywhere. Rapid download to all my connected electronics. And you cannot go wrong with free.\n",
            "\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Analysis:\n",
            "  Review 1 has: 14 shingles\n",
            "  Review 2 has: 11 shingles\n",
            "  In common:    10 shingles (66.7%)\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "Common shingles (first 10):\n",
            "  1. 'cannot go wrong'\n",
            "  2. 'electronics cannot go'\n",
            "  3. 'get kindle transport'\n",
            "  4. 'kindle transport everywhere'\n",
            "  5. 'easy get kindle'\n",
            "  6. 'everywhere rapid download'\n",
            "  7. 'transport everywhere rapid'\n",
            "  8. 'rapid download connected'\n",
            "  9. 'connected electronics cannot'\n",
            "  10. 'download connected electronics'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# 26. DOWNLOAD RESULTS\n",
        "# Save all similar pairs to files - WITH FULL TEXT\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "if len(results_df) > 0:\n",
        "\n",
        "    print(\"=\"*80)\n",
        "    print(\"SAVING RESULTS WITH FULL TEXT\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    # FILE 1: Basic results (compact) - with full text\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "    # Create export with key columns\n",
        "    export_df = results_df[['key1', 'key2', 'similarity']].copy()\n",
        "\n",
        "    # Add shingle counts\n",
        "    export_df['shingles1'] = export_df['key1'].map(lambda k: len(shingle_dict[k]))\n",
        "    export_df['shingles2'] = export_df['key2'].map(lambda k: len(shingle_dict[k]))\n",
        "\n",
        "    # Save to CSV (without text for compact file)\n",
        "    export_df.to_csv('similar_pairs.csv', index=False)\n",
        "\n",
        "    print(f\"\\nâœ“ File 1: 'similar_pairs.csv'\")\n",
        "    print(f\"  Rows: {len(export_df):,}\")\n",
        "    print(f\"  Columns: {list(export_df.columns)}\")\n",
        "    print(f\"  (Compact version without text)\")\n",
        "\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    # FILE 2: With FULL TEXT (no truncation)\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "    # Add COMPLETE text - NO CHARACTER LIMIT\n",
        "    export_full = export_df.copy()\n",
        "    export_full['text1_full'] = results_df['text1']\n",
        "    export_full['text2_full'] = results_df['text2']\n",
        "\n",
        "    # Save with FULL text\n",
        "    export_full.to_csv('similar_pairs_FULL_TEXT.csv', index=False)\n",
        "\n",
        "    print(f\"\\nâœ“ File 2: 'similar_pairs_FULL_TEXT.csv'\")\n",
        "    print(f\"  Rows: {len(export_full):,}\")\n",
        "    print(f\"  Includes COMPLETE review text (no truncation)\")\n",
        "\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    # FILE 3: Human-readable text report with FULL TEXT\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "    # Write detailed report to text file\n",
        "    with open('similar_pairs_FULL_REPORT.txt', 'w', encoding='utf-8') as f:\n",
        "        f.write(\"=\"*80 + \"\\n\")\n",
        "        f.write(\"SIMILARITY RESULTS - COMPLETE REPORT\\n\")\n",
        "        f.write(\"=\"*80 + \"\\n\\n\")\n",
        "\n",
        "        f.write(f\"Total documents analyzed: {len(df_sample):,}\\n\")\n",
        "        f.write(f\"Similar pairs found: {len(results_df):,}\\n\")\n",
        "        f.write(f\"Similarity threshold: {THRESHOLD}\\n\\n\")\n",
        "\n",
        "        f.write(f\"Similarity Statistics:\\n\")\n",
        "        f.write(f\"  Min:    {results_df['similarity'].min():.3f}\\n\")\n",
        "        f.write(f\"  Max:    {results_df['similarity'].max():.3f}\\n\")\n",
        "        f.write(f\"  Mean:   {results_df['similarity'].mean():.3f}\\n\")\n",
        "        f.write(f\"  Median: {results_df['similarity'].median():.3f}\\n\\n\")\n",
        "\n",
        "        f.write(\"=\"*80 + \"\\n\")\n",
        "        f.write(\"DETAILED PAIRS WITH FULL TEXT\\n\")\n",
        "        f.write(\"=\"*80 + \"\\n\\n\")\n",
        "\n",
        "        # Write ALL pairs with FULL text\n",
        "        for i in range(len(results_df)):\n",
        "            row = results_df.iloc[i]\n",
        "\n",
        "            f.write(\"\\n\" + \"â”€\"*80 + \"\\n\")\n",
        "            f.write(f\"PAIR #{i+1}\\n\")\n",
        "            f.write(\"â”€\"*80 + \"\\n\")\n",
        "            f.write(f\"Similarity Score: {row['similarity']:.3f}\\n\")\n",
        "            f.write(f\"Key 1: {row['key1']}\\n\")\n",
        "            f.write(f\"Key 2: {row['key2']}\\n\\n\")\n",
        "\n",
        "            f.write(\"REVIEW 1 (COMPLETE TEXT):\\n\")\n",
        "            f.write(\"-\"*80 + \"\\n\")\n",
        "            f.write(f\"{row['text1']}\\n\\n\")\n",
        "\n",
        "            f.write(\"REVIEW 2 (COMPLETE TEXT):\\n\")\n",
        "            f.write(\"-\"*80 + \"\\n\")\n",
        "            f.write(f\"{row['text2']}\\n\\n\")\n",
        "\n",
        "            # Add shingle analysis\n",
        "            s1 = shingle_dict[row['key1']]\n",
        "            s2 = shingle_dict[row['key2']]\n",
        "            common = s1 & s2\n",
        "\n",
        "            f.write(\"SIMILARITY ANALYSIS:\\n\")\n",
        "            f.write(f\"  Review 1 shingles: {len(s1)}\\n\")\n",
        "            f.write(f\"  Review 2 shingles: {len(s2)}\\n\")\n",
        "            f.write(f\"  Common shingles: {len(common)} ({len(common)/len(s1|s2)*100:.1f}%)\\n\")\n",
        "            f.write(f\"  Unique to review 1: {len(s1-s2)}\\n\")\n",
        "            f.write(f\"  Unique to review 2: {len(s2-s1)}\\n\\n\")\n",
        "\n",
        "            # Show some common shingles\n",
        "            if common:\n",
        "                f.write(\"Sample common shingles:\\n\")\n",
        "                for idx, shingle in enumerate(list(common)[:10], 1):\n",
        "                    f.write(f\"  {idx}. '{shingle}'\\n\")\n",
        "\n",
        "            f.write(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "\n",
        "    print(f\"\\nâœ“ File 3: 'similar_pairs_FULL_REPORT.txt'\")\n",
        "    print(f\"  Human-readable report with COMPLETE text\")\n",
        "    print(f\"  Includes detailed analysis for all pairs\")\n",
        "\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    # FILE 4: Summary statistics\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "    with open('summary_statistics.txt', 'w', encoding='utf-8') as f:\n",
        "        f.write(\"SUMMARY STATISTICS\\n\")\n",
        "        f.write(\"=\"*50 + \"\\n\\n\")\n",
        "\n",
        "        f.write(f\"Dataset Information:\\n\")\n",
        "        f.write(f\"  Total documents: {len(df_sample):,}\\n\")\n",
        "        f.write(f\"  Candidate pairs checked: {len(clean_pairs):,}\\n\")\n",
        "        f.write(f\"  Similar pairs found: {len(results_df):,}\\n\")\n",
        "        f.write(f\"  Threshold: {THRESHOLD}\\n\\n\")\n",
        "\n",
        "        f.write(f\"Similarity Distribution:\\n\")\n",
        "        f.write(f\"  Minimum:  {results_df['similarity'].min():.3f}\\n\")\n",
        "        f.write(f\"  Maximum:  {results_df['similarity'].max():.3f}\\n\")\n",
        "        f.write(f\"  Mean:     {results_df['similarity'].mean():.3f}\\n\")\n",
        "        f.write(f\"  Median:   {results_df['similarity'].median():.3f}\\n\")\n",
        "        f.write(f\"  Std Dev:  {results_df['similarity'].std():.3f}\\n\\n\")\n",
        "\n",
        "        f.write(f\"Review Length Statistics:\\n\")\n",
        "        f.write(f\"  Avg text1 length: {results_df['text1'].str.len().mean():.0f} chars\\n\")\n",
        "        f.write(f\"  Avg text2 length: {results_df['text2'].str.len().mean():.0f} chars\\n\")\n",
        "\n",
        "    print(f\"\\nâœ“ File 4: 'summary_statistics.txt'\")\n",
        "    print(f\"  Statistical summary\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8DQ0SPPiDTq",
        "outputId": "114e2db4-11ab-456b-df7f-d64b3408680b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "SAVING RESULTS WITH FULL TEXT\n",
            "================================================================================\n",
            "\n",
            "âœ“ File 1: 'similar_pairs.csv'\n",
            "  Rows: 331\n",
            "  Columns: ['key1', 'key2', 'similarity', 'shingles1', 'shingles2']\n",
            "  (Compact version without text)\n",
            "\n",
            "âœ“ File 2: 'similar_pairs_FULL_TEXT.csv'\n",
            "  Rows: 331\n",
            "  Includes COMPLETE review text (no truncation)\n",
            "\n",
            "âœ“ File 3: 'similar_pairs_FULL_REPORT.txt'\n",
            "  Human-readable report with COMPLETE text\n",
            "  Includes detailed analysis for all pairs\n",
            "\n",
            "âœ“ File 4: 'summary_statistics.txt'\n",
            "  Statistical summary\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}